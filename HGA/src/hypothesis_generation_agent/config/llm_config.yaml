
# Default LLM Configuration
default:
  model: "gpt-4o-mini"
  temperature: 0.7
  max_tokens: 4000
  top_p: 1.0
  frequency_penalty: 0.0
  presence_penalty: 0.0
  timeout: 60

# Alternative LLM Configurations
models:
  # High-performance model for complex reasoning tasks
  high_performance:
    model: "gpt-4o"
    temperature: 0.5
    max_tokens: 8000
    top_p: 0.95
    frequency_penalty: 0.0
    presence_penalty: 0.0
    timeout: 120
  
  # Fast model for simple tasks
  fast:
    model: "gpt-3.5-turbo"
    temperature: 0.7
    max_tokens: 2000
    top_p: 1.0
    frequency_penalty: 0.0
    presence_penalty: 0.0
    timeout: 30
  
  # Creative model for hypothesis generation
  creative:
    model: "gpt-4o"
    temperature: 0.9
    max_tokens: 4000
    top_p: 0.9
    frequency_penalty: 0.2
    presence_penalty: 0.2
    timeout: 90
  
  # Precise model for statistical validation
  precise:
    model: "gpt-4o"
    temperature: 0.1
    max_tokens: 3000
    top_p: 1.0
    frequency_penalty: 0.0
    presence_penalty: 0.0
    timeout: 60

# Agent-specific LLM Configurations
agent_configs:
  context_extractor:
    use_model: "fast"
  
  hypothesis_generator:
    use_model: "creative"
  
  test_recommender:
    use_model: "default"
  
  reviewer:
    use_model: "default"
  
  statistical_validator:
    use_model: "precise"
  
  hypothesis_refiner:
    use_model: "default"
  
  hypothesis_librarian:
    use_model: "fast"

# API Configuration
api:
  openai:
    base_url: "https://api.openai.com/v1"
    organization: null  # Set if using an organization ID
    max_retries: 3
    retry_delay: 2  # seconds